{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kevinarnmark_lab3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 3: Iterative Methods**\n",
        "**Kevin Arnmark**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJipbXtnjrJZ"
      },
      "source": [
        "In this report I implement different iterative methods to solve both linear and nonlinear systems. I will be implementing four different methods. The jacobi iteration, Gauss-Seidel iteration, Newton's method and GMRES method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB2noTr1Oyo"
      },
      "source": [
        "A short statement on who is the author of the file, and if the code is distributed under a certain license. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdll1Xc9WP0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "aa244577-301d-42a9-b60a-38c0e6939102"
      },
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2020 Johan Hoffman (jhoffman@kth.se)\n",
        "\n",
        "# This file is part of the course DD2365 Advanced Computation in Fluid Mechanics\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "In this report I will construct the following algorithms:\n",
        "\n",
        "\n",
        "1. **Function:** Jacobi iteration for Ax=b\n",
        "\n",
        "  **Input:** matrix A, vector b\n",
        "\n",
        "  **Output:** vector x\n",
        "\n",
        "  **Test:** convergence of residual || Ax-b ||, || x-y || for manufactured/exact solution y \n",
        "\n",
        "2. **Function:** Gauss-Seidel iteration for Ax=b\n",
        "\n",
        "  **Input:** matrix A, vector b\n",
        "\n",
        "  **Output:** vector x\n",
        "\n",
        "  **Test:** convergence of residual || Ax-b ||, || x-y || for manufactured/exact solution y\n",
        "\n",
        "3. **Function:** Newton's method for scalar nonlinear equation f(x)=0\n",
        "\n",
        "  **Input:** scalar function f(x)\n",
        "\n",
        "  **Output:** real number x\n",
        "\n",
        "  **Test:** convergence of residual |f(x)|, |x-y| for manufactured/exact solution y\n",
        "\n",
        "**Extra assignment:**\n",
        "\n",
        "4. **Function:** GMRES method for Ax=b\n",
        "\n",
        "  **Input:** matrix A, vector b\n",
        "\n",
        "  **Output:** vector x \n",
        "\n",
        "  **Test:** convergence of residual || Ax-b ||, || x-y || for manufactured/exact solution y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCaYOnCGH6mC"
      },
      "source": [
        "Throughout the report I am using the value of $1^{-7}$ for the tolerance of the stopping criterium of the iterative methods. This is to ensure a low enough tolerance to pass the tests. If the tolerance is decreased, the precision is increased."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxspIhFa47r6"
      },
      "source": [
        "**Jacobi iteration**\r\n",
        "\r\n",
        "The jacobi iteration is equivalent to a left preconditioned Richardson iteration with $\\alpha = 1$. The jacobi iteration is a preconditioned Richardson iteration with $B = D^{-1}$, where $D$ is a matrix with identical diagonal elements as $A$ (Chapter 7.6-7.7). The convergence criteria for this method is $\\lvert\\lvert I - D^{-1}A \\rvert \\rvert < 1$. The base algorithm used for the richardson iteration is from Chapter 7.6 Algorithm 7.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CJXMCT1HTHL"
      },
      "source": [
        "def pre_richardson_iteration(A, B, b, alpha):\r\n",
        "  assert len(A) == len(A[0])\r\n",
        "\r\n",
        "  x = np.zeros(len(A))\r\n",
        "  tol = 1e-7\r\n",
        "\r\n",
        "  r = np.array([1, 1, 1]) # placeholder whit a norm larger than tol\r\n",
        "  while np.linalg.norm(r) > tol:\r\n",
        "    r = b - np.dot(A, x)\r\n",
        "    x = x + alpha * np.dot(B, r)\r\n",
        "\r\n",
        "  return x\r\n",
        "\r\n",
        "\r\n",
        "def jacobi_iteration(A, b):\r\n",
        "  id = np.identity(len(A))\r\n",
        "  B = np.diag(1. / np.diag(A)) # Taking 1/x for each x in the diagonal of A, the inverse of an diagonal matrix\r\n",
        "  assert np.linalg.norm(id - np.matmul(B, A)) < 1 # Checking the convergence criteria\r\n",
        "\r\n",
        "  return pre_richardson_iteration(A, B, b, 1)\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgY2hHUWasE7"
      },
      "source": [
        "**Gauss-Seidel iteration** Solving $Ax=b$\r\n",
        "\r\n",
        "Gauss-Seidel iteration is preconditioned Richardson iteration with $B=L^{-1}$ and $\\alpha = 1$ with the convergence criterion $\\lvert\\lvert I - L^{-1}A \\rvert \\rvert < 1$. L is the lower triangular matrix constructed from $A$ by zeroing out all the entries above the diagonal (Chapter 7.7 Example 7.9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GUQ1S4Carj7"
      },
      "source": [
        "def forward_substitution(L, b):\r\n",
        "  n = len(b)\r\n",
        "  x = np.zeros(n)\r\n",
        "  x[0] = b[0] / L[0,0]\r\n",
        "\r\n",
        "  for i in range(1, n):\r\n",
        "    s = 0\r\n",
        "    for j in range(i):\r\n",
        "      s += L[i,j]*x[j]\r\n",
        "    x[i] = (b[i] - s) / L[i, i]\r\n",
        "  return x\r\n",
        "\r\n",
        "def gauss_seidel_iteration(A, b):\r\n",
        "  n = len(A)\r\n",
        "  id = np.identity(n)\r\n",
        "  L = np.tril(A)\r\n",
        "  B = np.zeros((L.shape))\r\n",
        "  for i in range(n):\r\n",
        "    B[:,i] = forward_substitution(L, id[:,i])\r\n",
        "\r\n",
        "  assert np.linalg.norm(id - np.matmul(B, A)) < 1 # Checking the convergence criteria\r\n",
        "  return pre_richardson_iteration(A, B, b, 1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8Z9lVe1yQe"
      },
      "source": [
        "**Newtons Method**\r\n",
        "For solving scalar nonlinear equation $f(x)=0$. \r\n",
        "\r\n",
        "This algorithm is built upon Algorithm 8.2 in Chapter 8.3. To calculate the derivative of f(x) I used Theorem 8.4 (Mean value theorem) in Chapter 8.2 to get an approximation of the derivative. To get the a good approximation I used the value closest to 0 python allows to calculate a divison as the difference in the input values of the functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFY8GStu17iU"
      },
      "source": [
        "def newtons_method(fnc, x0):\r\n",
        "  x = x0\r\n",
        "  tol = 1e-7\r\n",
        "  h = 1e-15 # closest number to zero that does not give divison by zero error\r\n",
        "  while np.abs(fnc(x)) > tol:\r\n",
        "    df = (fnc(x + h) - fnc(x)) / h\r\n",
        "    #print(df)\r\n",
        "    x -= fnc(x)/df\r\n",
        "  return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X96znF05ANw7"
      },
      "source": [
        "**GMRES**\r\n",
        "\r\n",
        "This algorithm is currently not working. I ran out of time to complete it. If you can easily spot the misstakes I would be grateful if you could comment what they are!\r\n",
        "\r\n",
        "This algorithm is based on Algorithm 7.2 in Chapter 7.8. The Arnoldi iteration that is used in the GMRES algorithm is based on Algorithm 7.3. To solve the least square problem I used a sequence of givens rotations to convert the Hessenberg matrix into an upper triangular matrix and then used backwards substitution to solve for $y$. The backward substitution algorithm is based on Algorithm 5.2 in Chapter 5.2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0N0sg7RAhVJ"
      },
      "source": [
        "def arnoldi_iteration(A, b, k):\r\n",
        "  n = len(A)\r\n",
        "  Q = np.zeros((n, k+1))\r\n",
        "  H = np.zeros((k+1, k))\r\n",
        "  Q[:,0] = b/np.linalg.norm(b)\r\n",
        "  for j in range(k):\r\n",
        "    v = np.dot(A, Q[:,j])\r\n",
        "    for i in range(j):\r\n",
        "      H[i,j] = np.dot(Q[:,i], v)\r\n",
        "      v -= H[i,k]*Q[:,i]\r\n",
        "    H[j+1,j] = np.linalg.norm(v)\r\n",
        "    Q[:,j+1] = v[:] / H[j+1,j]\r\n",
        "  return Q, H\r\n",
        "\r\n",
        "\r\n",
        "def givens_rotation(H, k, i):\r\n",
        "  x1 = H[0,0]\r\n",
        "  x2 = H[1,0]\r\n",
        "  norm = np.linalg.norm(H[:,0])\r\n",
        "  c = x1 / norm\r\n",
        "  s = -(x2 / norm)\r\n",
        "  G = np.identity(k)\r\n",
        "  G[i:i+2,i:i+2] = np.array([[c,-s], [s,c]])\r\n",
        "  return G\r\n",
        "\r\n",
        "def backward_substitution(U, b):\r\n",
        "  n = len(b)\r\n",
        "  x = np.zeros((n, ))\r\n",
        "  x[n - 1] = b[n - 1] / U[n-1, n-1]\r\n",
        "  for i in range(n - 2, -1, -1):\r\n",
        "    s = 0\r\n",
        "    for j in range(i + 1, n):\r\n",
        "      s += U[i, j] * x[j]\r\n",
        "    x[i] = (b[i] - s) / U[i, i]\r\n",
        "  return x\r\n",
        "\r\n",
        "\r\n",
        "def least_squares_problem(H, v):\r\n",
        "  n = len(H)\r\n",
        "  A = np.zeros((2,))\r\n",
        "  Gk = np.identity(n)\r\n",
        "  \r\n",
        "  for k in range(n-1):\r\n",
        "    G = givens_rotation(H[k:k+2,k:k+2], n, k)\r\n",
        "    Gk = np.matmul(G, Gk)\r\n",
        "\r\n",
        "  H = np.matmul(Gk,H)\r\n",
        "  y = backward_substitution(H, np.dot(Gk, v))\r\n",
        "  return y\r\n",
        "\r\n",
        "\r\n",
        "def gmres(A, b):\r\n",
        "  n = len(A)\r\n",
        "  assert len(A[0]) == n\r\n",
        "  assert len(b) == n\r\n",
        "  k = 0\r\n",
        "  tol = 1e-6\r\n",
        "  r = np.array([1,1,1])\r\n",
        "  while (np.linalg.norm(r) / np.linalg.norm(b)) > tol:\r\n",
        "    k += 1\r\n",
        "    e1 = np.zeros((k + 1,))\r\n",
        "    e1[0] = 1\r\n",
        "\r\n",
        "    Q, H = arnoldi_iteration(A, b, k)\r\n",
        "    y = least_squares_problem(H, np.linalg.norm(b)*e1)\r\n",
        "    r = np.linalg.norm(b)*e1 - np.dot(H, y)\r\n",
        "  \r\n",
        "  x = np.dot(Q[:,:k-1], y)\r\n",
        "  return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt4MijQxI7P3"
      },
      "source": [
        "# Tests:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4rBEfYmVBF-"
      },
      "source": [
        "Below are some basic tests to ensure the algorithms are working as intended. The tolerance is at 7 decimals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXJtLv0VJFzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4ae8d7-1341-4d1b-a51e-164f5ee3a6e1"
      },
      "source": [
        "# Jacobi iteration tests\r\n",
        "\r\n",
        "# Constructing solution\r\n",
        "A = np.array([[8,1,0], [0,7,1], [1,0,9]]) # Diagonal dominant matrix\r\n",
        "y = [3, -2, 1]\r\n",
        "b = np.dot(A, y) \r\n",
        "\r\n",
        "x = jacobi_iteration(A, b)\r\n",
        "\r\n",
        "np.testing.assert_almost_equal(np.linalg.norm(np.dot(A, x) - b), 0) # Testing the convergence of the residual\r\n",
        "np.testing.assert_almost_equal(np.linalg.norm(x - y), 0) # Testing the difference between the exact solution and the jacobi iteration solution\r\n",
        "\r\n",
        "print(\"Jacobi iteration tests passed\") # Prints if nothing fails\r\n",
        "\r\n",
        "# Gauss-Seidel iterations\r\n",
        "A = np.array([[2,1,0], [1,3,-1], [1,2,4]])\r\n",
        "y = [1, -4, 2]\r\n",
        "b = np.dot(A, y) \r\n",
        "\r\n",
        "x = gauss_seidel_iteration(A, b)\r\n",
        "\r\n",
        "np.testing.assert_almost_equal(np.linalg.norm(np.dot(A, x) - b), 0) # Testing the convergence of the residual\r\n",
        "np.testing.assert_almost_equal(np.linalg.norm(x - y), 0) # Testing the difference between the exact solution and the gauss-seidel iteration solution\r\n",
        "\r\n",
        "print(\"Gauss-Seidel iteration tests passed\") # Prints if nothing fails\r\n",
        "\r\n",
        "# Newtons method for scalar nonlinear equation f(x)=0 tests\r\n",
        "def fnc1(x):\r\n",
        "  return x**2 - 4\r\n",
        "\r\n",
        "def fnc2(x):\r\n",
        "  return np.cos(x)\r\n",
        "\r\n",
        "x1 = newtons_method(fnc1, 1)\r\n",
        "x2 = newtons_method(fnc2, 1)\r\n",
        "\r\n",
        "np.testing.assert_almost_equal(np.abs(fnc1(x1)), 0) # Testing the convergence of the residual\r\n",
        "np.testing.assert_almost_equal(np.abs(fnc2(x2)), 0) # Testing the convergence of the residual\r\n",
        "\r\n",
        "np.testing.assert_almost_equal(np.abs(x1 - 2), 0) # Testing the difference between the exact solution and the newton's method solution\r\n",
        "np.testing.assert_almost_equal(np.abs(x2 - np.pi/2), 0) # Testing the difference between the exact solution and the newton's method solution\r\n",
        "\r\n",
        "print(\"Newton's method tests passed\") # Prints if nothing fails\r\n",
        "\r\n",
        "# GMRES tests"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jacobi iteration tests passed\n",
            "Gauss-Seidel iteration tests passed\n",
            "Newton's method tests passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "The results are as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcsDSoRXHZe"
      },
      "source": [
        "If I had the time I would have written some more randomized tests and also measured the time of the algorithms to compare their performance."
      ]
    }
  ]
}