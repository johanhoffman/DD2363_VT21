{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RgtXlfYO_i7"
   },
   "source": [
    "# Lab 3: Iterative methods\n",
    "**Theo Puranen Ã…hfeldt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9x_J5FVuPzbm"
   },
   "source": [
    "# **Abstract**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UFTSzW7P8kL"
   },
   "source": [
    "The objective of this report is to implement iterative methods for solving linear and non-linear equations. The implementations are tested on randomly generated matrices. The testing indicates that the implementations are successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkT8J7uOWpT3"
   },
   "source": [
    "# **About the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Pdll1Xc9WP0e",
    "outputId": "6435158d-714b-4fa0-f688-bbd72fa2bc02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
    "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
    "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
    "\n",
    "# Copyright (C) 2020 Johan Hoffman (jhoffman@kth.se)\n",
    "\n",
    "# This file is part of the course DD2365 Advanced Computation in Fluid Mechanics\n",
    "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
    "#\n",
    "# This is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU Lesser General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# This template is maintained by Johan Hoffman\n",
    "# Please report problems to jhoffman@kth.se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28xLGz8JX3Hh"
   },
   "source": [
    "# **Set up environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2PYNusD08Wa"
   },
   "source": [
    "To have access to the neccessary modules you have to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xw7VlErAX7NS"
   },
   "outputs": [],
   "source": [
    "# Load neccessary modules.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnO3lhAigLev"
   },
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l5zMzgPlRAF6"
   },
   "source": [
    "In this report various iterative methods for solving both linear and non-linear equations are implemented. In particular, the iterative search methods for solving linear systems of equations, Jacobi iteration and Gauss-Seidel iteration, are implemented. Newton's method for solving nonlinear equations on the form $f(x) = 0$ where $f$ is a continous function, is implemented for both scalars and vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOQvukXZq5U5"
   },
   "source": [
    "# **Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF4iBj5VURZx"
   },
   "source": [
    "Numpy arrays are used to represent vectors and matrices. Jacobi iteration and Gauss-Seidel iteration are implemented as preconditioned Richardsson iteration and Newton's method is implemented using finite difference to approximate the derivative. Each implementation is tested by its produced solution, first that it is a solution by plugging it in, and also that it matches an already known exact solution. Since finite precision arithmetic is not perfect, tests do not check for equality but that the result is close enough to what is desired. Since the methods use a low tolerence level as a stopping criterion, the fact that they return a solution means that they have converged. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobi iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement Jacobi iteration using Richardson iteration with a Jacobi preconditioner. First we implement the Richardson iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "def richardson_iteration(A, b, alpha):\n",
    "    n, m = A.shape\n",
    "    assert np.linalg.norm(np.identity(n) - alpha * A, ord=2) < 1, print(\"Convergence criteria not fullfilled\")\n",
    "    x = np.zeros(m)\n",
    "    r = b\n",
    "    while np.linalg.norm(r) > 1e-10:\n",
    "        r = b - np.matmul(A, x)\n",
    "        x = x + alpha * r\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement Jacobi iteration is now a simple matter of preconditioning with the matrix $B = diag(A)^{-1}$ and choosing $\\alpha = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_iteration(A, b):\n",
    "    B = np.diag(1./np.diag(A))\n",
    "    return richardson_iteration(np.matmul(B,A), np.matmul(B,b), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the method on randomly generated vectors and matrices. Since the Jacobi iteration is only sure to converge if $\\|I - D^{-1}A\\| < 1$, where $D = diag(A)$, we only expect the method to converge when this is true. To increase the chances of generating a matrix fulfilling the criterion, the matrix is first filled with small numbers, and afterwards bigger numbers are added to the diagonal. The tests are generalized so that they can be reused for the Gauss-Seidel iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran  57  tests.\n"
     ]
    }
   ],
   "source": [
    "def verify_solver_residual(A, b, solver):\n",
    "    x = solver(A, b)\n",
    "    assert np.linalg.norm(np.matmul(A, x) - b) < 1e-10\n",
    "    \n",
    "def verify_solver_exact(A, y, solver):\n",
    "    b = np.matmul(A, y)\n",
    "    x = solver(A, b)\n",
    "    assert np.linalg.norm(x - y) < 1e-10\n",
    "    \n",
    "def test_jacobi_iteration(tests, rows):\n",
    "    num_runs = 0\n",
    "    for _ in range(tests):\n",
    "        test_mat = np.random.random((rows, rows)) / 100\n",
    "        extra_diag = np.diag(np.random.random((rows,)))\n",
    "        test_mat += extra_diag\n",
    "        test_vec = np.random.random((rows,))\n",
    "        if np.linalg.norm(np.identity(rows) - np.matmul(np.linalg.inv(np.diag(np.diag(test_mat))), test_mat), ord=2) < 1:\n",
    "            verify_solver_residual(test_mat, test_vec, jacobi_iteration)\n",
    "            verify_solver_exact(test_mat, test_vec, jacobi_iteration)\n",
    "            num_runs += 1\n",
    "    print(\"Ran \", num_runs, \" tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss-Seidel iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Richardson iteration, we can achieve Gauss-Seidel iteration by preconditioning with $B = L^{-1}$, where $L$ is the lower triangular matrix obtained from the matrix $A$ by zeroing out all entries above the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel_iteration(A, b):\n",
    "    B = np.linalg.inv(np.tril(A))\n",
    "    return richardson_iteration(np.matmul(B,A), np.matmul(B,b), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reuse the tests from the Jacobi iteration, but with our new Gauss-Seidel iteration and its convergence criterion $\\|I - D^{-1}A\\| < 1$ where $D = L$ as previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran  38  tests.\n"
     ]
    }
   ],
   "source": [
    "def test_gauss_seidel_iteration(tests, rows):\n",
    "    num_runs = 0\n",
    "    for _ in range(tests):\n",
    "        test_mat = np.random.random((rows, rows)) / 20\n",
    "        extra_diag = np.diag(np.random.random((rows,)) + 0.1)\n",
    "        test_mat += extra_diag\n",
    "        test_vec = np.random.random((rows,))\n",
    "        L = np.linalg.inv(np.linalg.inv(np.tril(test_mat)))\n",
    "        if np.linalg.norm(np.identity(rows) - np.matmul(L, test_mat), ord=2) < 0.98:\n",
    "            verify_solver_residual(test_mat, test_vec, gauss_seidel_iteration)\n",
    "            verify_solver_exact(test_mat, test_vec, gauss_seidel_iteration)\n",
    "            num_runs += 1\n",
    "    print(\"Ran \", num_runs, \" tests.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's method (scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's method for solving scalar nonlinear equations can also be viewed as a form of Richard iteration where $\\alpha = -f'(x^{(k)})^{-1}$. However, since this is a function of $x^{(k)}$, it is not possible to reuse our Richardson iteration implementation. We also need to be able to compute the derivative of $f$, which would ideally be done analytically. However, for our implementation to be able to handle an arbitrary function this is not feasable, so we will use finite difference instead.\n",
    "\n",
    "Since convergence for Newton's method depends on the initial value of $x$ that has to be decided based on the particular function, this is added as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_difference(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "def newtons_method_scalar(f, x0):\n",
    "    x = x0\n",
    "    while np.abs(f(x)) > 1e-10:\n",
    "        df = finite_difference(f, x, 1e-8)\n",
    "        x = x - f(x)/df\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is not as trivial to generate random non-linear functions as it is to generate linear ones, we will instead test on a few hand-picked examples that are easy to verify by hand. Otherwise the testing is very similar to the previous methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_newton_scalar_residual(f, x0):\n",
    "    x = newtons_method_scalar(f, x0)\n",
    "    assert np.abs(f(x)) < 1e-10\n",
    "    \n",
    "def verify_newton_scalar_exact(f, x0, y):\n",
    "    x = newtons_method_scalar(f, x0)\n",
    "    assert np.abs(x - y) < 1e-10\n",
    "    \n",
    "def test_newton_scalar():\n",
    "    f1 = lambda x: (x - 5)*(x + 3)\n",
    "    verify_newton_scalar_residual(f1, 4)\n",
    "    verify_newton_scalar_exact(f1, 4, 5)\n",
    "    verify_newton_scalar_residual(f1, -4)\n",
    "    verify_newton_scalar_exact(f1, -4, -3)\n",
    "    \n",
    "    verify_newton_scalar_residual(np.sin, 1)\n",
    "    verify_newton_scalar_exact(np.sin, 1, 0)\n",
    "    verify_newton_scalar_residual(np.sin, 3)\n",
    "    verify_newton_scalar_exact(np.sin, 3, np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's method (vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newton's method to solve vector nonlinear equations is exactly the same as for scalars but where $\\alpha = -f'(x^{(k)})^{-1}$ has been replaced by the matrix $A = -f'(x^{(k)})^{-1}$, where $f'(x^{(k)})$ is the Jacobian of $f$ evaluated at $x^{(k)}$. For the same reasons as before, we will compute the Jacobian using finite difference instead of computing it analytically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian(f, x, h):\n",
    "    return np.array([(f(x + dx) - f(x))/h for dx in h * np.identity(x.size)]).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of computing the inverse of the Jacobian directly in the update equation $x^{(k+1)} = x^{(k)} - f'(x^{(k)})^{-1} f(x^{(k)})$, we solve the linear equation $\\Delta x^{(k+1)} = x^{(k+1)} - x^{(k)} = - f'(x^{(k)})^{-1} f(x^{(k)}) \\Leftrightarrow f'(x^{(k)})\\Delta x^{(k+1)} = - f(x^{(k)})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newtons_method_vector(f, x0):\n",
    "    x = x0\n",
    "    while np.linalg.norm(f(x)) > 1e-10:\n",
    "        df = jacobian(f, x, 1e-8)\n",
    "        dx = np.linalg.solve(df, -f(x))\n",
    "        x = x + dx\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests are just like for the scalar version, just with functions in multiple variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_newton_vector_residual(f, x0):\n",
    "    x = newtons_method_vector(f, x0)\n",
    "    assert np.linalg.norm(f(x)) < 1e-10\n",
    "    \n",
    "def verify_newton_vector_exact(f, x0, y):\n",
    "    x = newtons_method_vector(f, x0)\n",
    "    assert np.linalg.norm(x - y) < 1e-10\n",
    "    \n",
    "def test_newton_vector():\n",
    "    f1 = lambda x: np.array([x[0]*(3*x[1] + 6), x[1]*(4 - 2*x[0])])\n",
    "    verify_newton_vector_residual(f1, np.array([0.5, 0.5]))\n",
    "    verify_newton_vector_exact(f1, np.array([0.5, 0.5]), np.array([0, 0]))\n",
    "    verify_newton_vector_residual(f1, np.array([3, -3]))\n",
    "    verify_newton_vector_exact(f1, np.array([3, -3]), np.array([2, -2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsQLT38gVbn_"
   },
   "source": [
    "# **Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell runs all test and shows that the implementions are successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran  59  tests.\n",
      "Ran  36  tests.\n",
      "OK! completed all tests\n"
     ]
    }
   ],
   "source": [
    "test_jacobi_iteration(100,20)\n",
    "test_gauss_seidel_iteration(100,20)\n",
    "test_newton_scalar()\n",
    "test_newton_vector()\n",
    "print(\"OK! completed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_4GLBv0zWr7m"
   },
   "source": [
    "# **Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests are comprehensive enough to give a clear indication that the implementations are correct. The fact that the methods produce a solution means "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "template-report-lab-X.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
