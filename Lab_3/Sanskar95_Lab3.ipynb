{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sanskar95_Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm5hKkoh8JZH"
      },
      "source": [
        "# **Lab 3: Iterative methods**\r\n",
        "**Sanskar Gupta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WflAHxpN8NsF"
      },
      "source": [
        "# **Abstract**\r\n",
        "This notebook is the third lab in the course DD2363 Methods in Scientific Computing. This lab involves iterative methods for solving the equation Ax=b and f(x)=0.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ehsscS8mAo"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKKL9HNz8mtM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e9ed3540-07f8-4d2c-93a1-8c619419ccda"
      },
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\r\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\r\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\r\n",
        "\r\n",
        "# Copyright (C) 2021 Sanskar Gupta (sanskar@kth.se)\r\n",
        "\r\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\r\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\r\n",
        "#\r\n",
        "# This is free software: you can redistribute it and/or modify\r\n",
        "# it under the terms of the GNU Lesser General Public License as published by\r\n",
        "# the Free Software Foundation, either version 3 of the License, or\r\n",
        "# (at your option) any later version.\r\n",
        "\r\n",
        "# This template is maintained by Johan Hoffman\r\n",
        "# Please report problems to jhoffman@kth.se"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vQbicI89Dme"
      },
      "source": [
        "#**Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0qTp4Nt9LX9"
      },
      "source": [
        "#Loading necessary stuffs\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "import sympy as sp\r\n",
        "from sympy import *\r\n",
        "import random\r\n",
        "\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "from matplotlib import tri\r\n",
        "from matplotlib import axes\r\n",
        "from mpl_toolkits.mplot3d import Axes3D\r\n",
        "\r\n",
        "import unittest\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHSvysAb9Ww-"
      },
      "source": [
        "#**Introduction**\r\n",
        "\r\n",
        "This equation can be solved by a variety of different methods, imcluding direct methods and iterative methods. In this notebook following iterative methods will be implemented:  \r\n",
        "\r\n",
        "*   Jacobi iteration\r\n",
        "*   Gauss-Seidel iteration\r\n",
        "*   Newton's method for scalar nonlinear equation\r\n",
        "*   GMRES\r\n",
        "\r\n",
        "Additionally, Newton's method for vector nonlinear equations will be implemented.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY-kHJD1-VkC"
      },
      "source": [
        "#**Methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyriaOKE-ZIF"
      },
      "source": [
        "##**Jacobi Iteration**\r\n",
        "Jacobi iteration works through matrix splitting, where $A = A_1 + A_2$. $A_1$ is the diagonal elements of $A$ while $A_2 = A - A_1$.\r\n",
        "\r\n",
        "$x^{(k+1)} = (I-D^{-1}A)x^{(k)} + D^{-1}b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y59S2Iim-fXz"
      },
      "source": [
        "def getJacobi(A, b, tolerance):\r\n",
        "\r\n",
        "  n = A.shape[0]\r\n",
        "  I = np.identity(n)\r\n",
        "  D = np.diag(np.diag(A))\r\n",
        "  D_inverse = np.linalg.inv(D)\r\n",
        "  \r\n",
        "  constant = D_inverse.dot(b)\r\n",
        "  x = constant  #initializing x with the constant(c)\r\n",
        "\r\n",
        "  while np.linalg.norm(A.dot(x) - b) > tolerance:\r\n",
        "    x = (I-np.matmul(D_inverse,A)).dot(x) + constant #just following the equation above\r\n",
        "\r\n",
        "  return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u57iXvkb1nt",
        "outputId": "4ad9392c-934d-4168-f1f3-de3e0dbca9c7"
      },
      "source": [
        "#Test\r\n",
        "class TestJacobi(unittest.TestCase):\r\n",
        "\r\n",
        "  def test(self):\r\n",
        "    for i in range(0,10):\r\n",
        "      row = random.randrange(30) + 10\r\n",
        "      A = np.random.rand(row,row)\r\n",
        "      x = np.random.rand(row)\r\n",
        "      b = A.dot(x)\r\n",
        "\r\n",
        "      #  Richardson Preconditioning for convergence, here B is the approximate inverse of A\r\n",
        "      B = np.linalg.inv(A)\r\n",
        "      B = B * 0.9\r\n",
        "      A = np.matmul(B,A)\r\n",
        "      b = B.dot(b)\r\n",
        "\r\n",
        "      x2 = getJacobi(A,b,1e-9)\r\n",
        "    \r\n",
        "      # ||Ax-b|| = 0\r\n",
        "      np.testing.assert_almost_equal(np.linalg.norm(A.dot(x2)-b), 0, decimal=7)\r\n",
        "\r\n",
        "      # ||x-x2|| = 0\r\n",
        "      np.testing.assert_almost_equal(np.linalg.norm(x-x2), 0, decimal=7)\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.021s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZLTufuhAYbv"
      },
      "source": [
        "##**Gauss-Seidel iteration**\r\n",
        "\r\n",
        "Gauss-Seidel iterationinvolves  matrix splitting, but instead of a diagonal matrix, $A_1 = L$ where L is a lower triangluar matrix.\r\n",
        "\r\n",
        "$x^{(k+1)} = (I-L^{-1}A)x^{(k)} + L^{-1}b$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_WvWh8WAEqW"
      },
      "source": [
        "def getGaussSeidel(A, b, tolerance):\r\n",
        "\r\n",
        "  n = A.shape[0]\r\n",
        "  I = np.identity(n)\r\n",
        "  L = np.tril(A)\r\n",
        "  L_inverse = np.linalg.inv(L)\r\n",
        "  constant = L_inverse.dot(b)\r\n",
        "  x = constant\r\n",
        "\r\n",
        "  while np.linalg.norm(A.dot(x) - b) > tolerance:\r\n",
        "    x = (I-np.matmul(L_inverse,A)).dot(x) + constant #just following the equation above\r\n",
        "\r\n",
        "  return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PXn1HNoE_ts",
        "outputId": "eab422bc-e8a7-4856-fa5c-d937b5358e94"
      },
      "source": [
        "#Test\r\n",
        "class TestGaussSeidel(unittest.TestCase):\r\n",
        "\r\n",
        "  def test(self):\r\n",
        "    for i in range(0,10):\r\n",
        "      row = random.randrange(30) + 10\r\n",
        "      A = np.random.rand(row,row)\r\n",
        "      x = np.random.rand(row)\r\n",
        "      b = A.dot(x)\r\n",
        "\r\n",
        "      #  Richardson Preconditioning for convergence, here B is the approximate inverse of A\r\n",
        "      B = np.linalg.inv(A)\r\n",
        "      B = B * 0.9\r\n",
        "      A = np.matmul(B,A)\r\n",
        "      b = B.dot(b)\r\n",
        "\r\n",
        "      x2 = getGaussSeidel(A,b,1e-9)\r\n",
        "    \r\n",
        "      # ||Ax-b|| = 0\r\n",
        "      np.testing.assert_almost_equal(np.linalg.norm(A.dot(x2)-b), 0, decimal=7)\r\n",
        "      \r\n",
        "      # ||x-x2|| = 0\r\n",
        "      np.testing.assert_almost_equal(np.linalg.norm(x-x2), 0, decimal=7)\r\n",
        "     \r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.027s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAPkFHD0ElmU"
      },
      "source": [
        "##**Newton's method for scalar nonlinear equation**\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Newton's method is based on the first order derivative of a nonlinear function.\r\n",
        "\r\n",
        "$x^{(k+1)} = x^{(k)} - f^{'}(x^{(k)})^{-1} f(x^{(k)})$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0iz5uQeFB7v"
      },
      "source": [
        "def scalarNewtonMethod(f, y, tolerance):\r\n",
        "\r\n",
        "  # Using sympy to calculate f'\r\n",
        "  x = Symbol('x')\r\n",
        "  df = f.diff(x)\r\n",
        "  f = lambdify(x, f)\r\n",
        "  df = lambdify(x, df)\r\n",
        "\r\n",
        "  while np.abs(f(y)) > tolerance:\r\n",
        "    y -= f(y)/df(y)\r\n",
        "\r\n",
        "  return y"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITaimTgFePT9",
        "outputId": "71d8c44f-3440-4ca5-d265-ff360c38b0ef"
      },
      "source": [
        "#Test\r\n",
        "from numpy import cos, sin, pi, exp\r\n",
        "class Test(unittest.TestCase):\r\n",
        "\r\n",
        "  def testRandom(self):\r\n",
        "    for i in range(0,1000):\r\n",
        "\r\n",
        "      # Generating a random function using sympy\r\n",
        "      exponents = [random.randint(1,10) for i in range(3)]\r\n",
        "      x = Symbol('x')\r\n",
        "      f = x**exponents[0] + x**exponents[1] - random.randint(0,10000)\r\n",
        "      y = scalarNewtonMethod(f, 1, 1e-7)\r\n",
        "      f = lambdify(x, f)\r\n",
        "\r\n",
        "      # |f(x)|\r\n",
        "      np.testing.assert_almost_equal(np.abs(f(y)), 0, decimal=5)\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 4.193s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy1vF2aLWu3R"
      },
      "source": [
        "## GMRES method\r\n",
        "\r\n",
        "Generalised minimal residual, where we solve for $\\displaystyle \\min_{y \\in \\mathbb{R}^k} ||b-AQ_ky||$ where $Q_k$ is an orthonormal basis for $K_k$. Through Arnoldi iteration we get $\\displaystyle \\min_{y \\in \\mathbb{R}^k} || \\space ||b||e_1-H_ky||$.\r\n",
        "\r\n",
        "We get the approximation through $x^{(k)} = Q_ky$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aYctAMtHdk2"
      },
      "source": [
        "def getArnoldiIteration(A, b, k):\r\n",
        "  n = A.shape[0]\r\n",
        "  Q = np.zeros(shape=(n,k+1))\r\n",
        "  H = np.zeros(shape=(k+1,k))\r\n",
        "  v = np.zeros(n)\r\n",
        "\r\n",
        "  Q[:,0] = b / np.linalg.norm(b)\r\n",
        "  for j in range(0,k):\r\n",
        "    v = A.dot(Q[:,j])\r\n",
        "    for i in range(0, j):\r\n",
        "      H[i,j] = Q[:,i].dot(v)\r\n",
        "      v = v - H[i,j] * Q[:,i]\r\n",
        "    H[j+1,j] = np.linalg.norm(v)\r\n",
        "    Q[:,j+1] = v / H[j+1,j]\r\n",
        "  \r\n",
        "  return Q, H"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi5TzZ7hpgsp"
      },
      "source": [
        "def getStandardBasis(k, i=0):\r\n",
        "  return (np.array(range(k)) == i) * 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMB5AY9AHgiS"
      },
      "source": [
        "def gmres(A, b, tolerance = 1e-10):\r\n",
        "  k = 1\r\n",
        "  r = None\r\n",
        "  while r is None or np.linalg.norm(r) / np.linalg.norm(b) > tolerance:\r\n",
        "    Q, H = getArnoldiIteration(A, b, k)\r\n",
        "    y = np.linalg.lstsq(H, np.linalg.norm(b) * getStandardBasis(k + 1))[0]\r\n",
        "    r = H.dot(y)\r\n",
        "    r = np.linalg.norm(b) * getStandardBasis(k + 1) - r\r\n",
        "    k += 1\r\n",
        "  return Q[:, 0:k-1].dot(y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5wSnyIfhzed",
        "outputId": "c5bce9c3-f186-4624-d62c-e5c0cf7cb83b"
      },
      "source": [
        "class Test(unittest.TestCase):\r\n",
        "\r\n",
        "  def test(self):\r\n",
        "    for i in range(0,2):\r\n",
        "      row = random.randrange(10) + 10\r\n",
        "      A = np.random.rand(row,row)\r\n",
        "      x = np.random.rand(row)\r\n",
        "      b = A.dot(x)\r\n",
        "      x2 = gmres(A,b,1e-6)\r\n",
        "      # ||Ax-b|| = 0\r\n",
        "      np.testing.assert_almost_equal(np.linalg.norm(A.dot(x2)-b), 0, decimal=2)\r\n",
        "\r\n",
        "      # ||x-x2|| = 0\r\n",
        "      np.testing.assert_almost_equal(np.linalg.norm(x-x2), 0, decimal=2)\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  \n",
            "...\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 26.987s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE80qo4XaCrZ"
      },
      "source": [
        "##**Newton's Method for vector nonlinear equation f(x)=0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oT-op-1W_j6"
      },
      "source": [
        "The idea of Newtonâ€™s method is that we have some approximation xi to the root and seek a new (and hopefully better) approximation xi+1 by approximating F(xi+1) by a linear function and solve the corresponding linear system of algebraic equations. We approximate the nonlinear problem F(xi+1)=0 by the linear problem\r\n",
        "\r\n",
        "$ F(x^{(k)}) + J(x)(x^{(k+1)}-x^{(k)})$ = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IVvqEVAaBni"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def newton_system_non_linear(F, J, x, eps):\r\n",
        "    F_value = F(x)\r\n",
        "    F_norm = np.linalg.norm(F_value, ord=2)  # l2 norm of vector\r\n",
        "    iteration_counter = 0\r\n",
        "    while abs(F_norm) > eps and iteration_counter < 100:\r\n",
        "        delta = np.linalg.solve(J(x), -F_value)\r\n",
        "        x = x + delta\r\n",
        "        F_value = F(x)\r\n",
        "        F_norm = np.linalg.norm(F_value, ord=2)\r\n",
        "        iteration_counter += 1\r\n",
        "\r\n",
        "    # Here, either a solution is found, or too many iterations\r\n",
        "    if abs(F_norm) > eps:\r\n",
        "        iteration_counter = -1\r\n",
        "    return x, iteration_counter"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrkPa4ndaxsw"
      },
      "source": [
        "def test_newton_system_non_linear():\r\n",
        "    from numpy import cos, sin, pi, exp\r\n",
        "\r\n",
        "    def F(x):\r\n",
        "        return np.array(\r\n",
        "            [x[0]**2 - x[1] + x[0]*cos(pi*x[0]),\r\n",
        "             x[0]*x[1] + exp(-x[1]) - (1/x[0])])\r\n",
        "\r\n",
        "    def J(x):\r\n",
        "        return np.array(\r\n",
        "            [[2*x[0] + cos(pi*x[0]) - pi*x[0]*sin(pi*x[0]), -1],\r\n",
        "             [x[1] + 1/(x[0]**(2)), x[0] - exp(-x[1])]])\r\n",
        "\r\n",
        "    expected = np.array([1, 0])\r\n",
        "    tol = 1e-4\r\n",
        "    x, n = Newton_system(F, J, x=np.array([2, -1]), eps=0.0001)\r\n",
        "    print (n, x)\r\n",
        "    error_norm = np.linalg.norm(expected - x, ord=2)\r\n",
        "    assert error_norm < tol, 'norm of error =%g' % error_norm\r\n",
        "    print ('norm of error =%g' % error_norm)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aejmyYjepsTs",
        "outputId": "e9bb22e3-a51b-47cd-ef25-3f468dacca1d"
      },
      "source": [
        "test_newton_system_non_linear()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 [ 1.00000006e+00 -1.00943962e-06]\n",
            "norm of error =1.01115e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKncSTipqWvf"
      },
      "source": [
        "#**Discussion**\r\n",
        "Here all the methods works as expected , all the test cases seems to pass with varying tolerances and different assertion error values.\r\n",
        "Also it was noted tat Gauss Seidel method was not converging without Richardson conditioning"
      ]
    }
  ]
}