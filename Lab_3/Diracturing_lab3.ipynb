{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Diracturing_lab3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OkT8J7uOWpT3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363_VT21/blob/Diracturing/Lab_3/Diracturing_lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 3**\n",
        "**Julius Andersson**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**\r\n",
        "In this lab 3 algorithms were constructed and tested. They were the Jacobi iteration, Gauss-Seidel iteration and lastly Newton's method. All algorithms did pass the tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB2noTr1Oyo"
      },
      "source": [
        "A short statement on who is the author of the file, and if the code is distributed under a certain license. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdll1Xc9WP0e"
      },
      "source": [
        "# Copyright (C) 2020 Julius Andersson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "#try:\n",
        "#    from dolfin import *; from mshr import *\n",
        "#except ImportError as e:\n",
        "#    !apt-get install -y -qq software-properties-common \n",
        "#    !add-apt-repository -y ppa:fenics-packages/fenics\n",
        "#    !apt-get update -qq\n",
        "#    !apt install -y --no-install-recommends fenics\n",
        "#    from dolfin import *; from mshr import *\n",
        "    \n",
        "#import dolfin.common.plotting as fenicsplot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**\r\n",
        "The theme for this lab was iterated methods. Previous we dealt with algorithms which produce exact solutions except for rounding errors. Now instead we use algorithms which should get closer to the solution for each iteration. The Jacobi iteration & Gauss-Seidel iteration algorithms are used for solving system of linear equations while the Newton algorithm are used to solve scalar nonlinear equation of the form f(x)=0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXc68GYHDmL2"
      },
      "source": [
        "1) Jacobi iteration \r\n",
        "\r\n",
        "The Jacobi iteration works similiar to the Richardson iteration but it is left preconditioned. Richardson iteration converges if $||I-\\alpha A||<1$ and this term is also connected to the rate of convergence. Jacobi iteration uses left precondition so the convergence critera instead is $||I-D^{-1}A||<1$, where D has the same diagonal as A but every other element is zero. If A is diagonally dominant this can be a way of lowering the convergence rate.\r\n",
        "\r\n",
        "The algorithm presented follows from the explanations at page 150-151 from the lecture notes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRmCgAnWrqBZ"
      },
      "source": [
        "def jacobi(A,b):\r\n",
        "  x=np.zeros(b.shape)\r\n",
        "  Tolerance=1e-10\r\n",
        "  \r\n",
        "  while np.linalg.norm(A@x-b)>Tolerance:\r\n",
        "    D=np.diagflat(np.diagonal(A))\r\n",
        "    Dinv=np.linalg.inv(D)\r\n",
        "    x+=-Dinv@A@x+Dinv@b\r\n",
        " \r\n",
        "  return x\r\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUg5vBdCs_gJ",
        "outputId": "678b66ee-954a-417e-be44-eefa4edb8a58"
      },
      "source": [
        "##### nothing too see#########\r\n",
        "A=np.array([[2,2,2],[1,2,4],[10,3,5]])\r\n",
        "np.linalg.eigvals(A)\r\n",
        "np.linalg.svd(A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx2emWWkD5QV"
      },
      "source": [
        "2) Gauss-Seidel iteration \r\n",
        "\r\n",
        "Similar to Jacobi iteration but uses another left preconditioner. Here we using L which is a lower triangular matrix. L is taken to be the lower triangular part of matrix A and zero elsewhere. While the jacobi iteration method can be made to be embarrasingly parallel the Gauss-Seidel can not. Instead it can be made to use lower storage [1]. \r\n",
        "\r\n",
        "The algorithm presented follows from the explanations at page 152 from the lecture notes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZBtOyfeEAxs"
      },
      "source": [
        "def gase(A,b):\r\n",
        "  x=np.zeros(b.shape)\r\n",
        "  Tolerance=1e-10\r\n",
        "  \r\n",
        "  while np.linalg.norm(A@x-b)>Tolerance:\r\n",
        "    L=np.tril(A)\r\n",
        "    Linv=np.linalg.inv(L)\r\n",
        "    x+=-Linv@A@x+Linv@b\r\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7E1CFYkUvyz"
      },
      "source": [
        "3) Newton's method\r\n",
        "\r\n",
        "Newton's method uses fixed point iteration $x^{(k+1)}=x^{(k)}+\\alpha f(x^{(k)})$. Newton method uses $\\alpha=-f'(x^{(k)})^{-1}$ which make it to a quadratic order of convergence (if f(x) meets certain requirements). \r\n",
        "\r\n",
        "The algorithm is from algorithm 8.2 in the lecture notes.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se9CC0VbU1X9"
      },
      "source": [
        "def der(f,x):\r\n",
        "  h=1e-8\r\n",
        "  return (f(x+h)-f(x))/h\r\n",
        "\r\n",
        "def newton(f,x0):\r\n",
        "  Tolerance=1e-10\r\n",
        "  x=x0\r\n",
        "  while abs(f(x))>Tolerance:\r\n",
        "    df=der(f,x)\r\n",
        "    x=x-f(x)/df\r\n",
        "  return x\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jejvJrbSVu12",
        "outputId": "06c5741e-4f8e-4a1d-d801-ce2f5577c4d1"
      },
      "source": [
        "##########Tests for jacobi and gauss-seidel ################\r\n",
        "A=np.array([[100,2,0],[5,55,2],[3,1,78]])\r\n",
        "y=np.array([3,5,2])\r\n",
        "b=A@y\r\n",
        "\r\n",
        "A2=np.array([[353,5,9],[5,152,10],[23,4,178]])\r\n",
        "y2=np.array([10,3,25])\r\n",
        "b2=A2@y2\r\n",
        "\r\n",
        "x=jacobi(A,b)\r\n",
        "x1=gase(A,b)\r\n",
        "\r\n",
        "x2=jacobi(A2,b2)\r\n",
        "x3=gase(A2,b2)\r\n",
        "\r\n",
        "\r\n",
        "assert np.isclose(np.linalg.norm(x-y),0,atol=1e-10)\r\n",
        "assert np.isclose(np.linalg.norm(x1-y),0,atol=1e-10)\r\n",
        "\r\n",
        "assert np.isclose(np.linalg.norm(x2-y2),0,atol=1e-10)\r\n",
        "assert np.isclose(np.linalg.norm(x3-y2),0,atol=1e-10)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "########### Tests for Newton method ################\r\n",
        "def f1(x):\r\n",
        "  return math.cos(x)\r\n",
        "\r\n",
        "def f2(x):\r\n",
        "  return x-3\r\n",
        "\r\n",
        "def f3(x):\r\n",
        "  return x**2-1\r\n",
        "\r\n",
        "\r\n",
        "assert np.isclose(abs(newton(f1,0.5)-np.pi/2),0,atol=1e-10)\r\n",
        "assert np.isclose(abs(newton(f2,0.5)-3),0,atol=1e-10)\r\n",
        "assert np.isclose(abs(newton(f3,0.5)-1),0,atol=1e-10)\r\n",
        "\r\n",
        "\r\n",
        "print(\"ok\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asoZX58kkb3H"
      },
      "source": [
        "As can be seen above all methods passed the tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**\r\n",
        "There is not much to say about the results. We could see all methods converge to the actual value. One thing one can notice is that newton's method only finds 1 solution and it might be hard to find all roots. Improvements could be to calculate if the convergence criteria is fulfilled before calling the actual algorithm or to introduce a max time each algorithm can run.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vcIILuQYsEA"
      },
      "source": [
        "# **APPENDIX**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhdm6dWMPyNH"
      },
      "source": [
        "# **References**\r\n",
        "[1] https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method"
      ]
    }
  ]
}