{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6RgtXlfYO_i7"
   },
   "source": [
    "# **Lab 2: Matrix factorization**\n",
    "**Theo Puranen Åhfeldt**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9x_J5FVuPzbm"
   },
   "source": [
    "# **Abstract**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UFTSzW7P8kL"
   },
   "source": [
    "The objective of this report is to implement algorithms for solving or related to solving linear equations. The implementations are tested on randomly generated matrices. The testing indicates that the implementations are successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkT8J7uOWpT3"
   },
   "source": [
    "# **About the code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Pdll1Xc9WP0e",
    "outputId": "6435158d-714b-4fa0-f688-bbd72fa2bc02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
    "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
    "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
    "\n",
    "# Copyright (C) 2020 Johan Hoffman (jhoffman@kth.se)\n",
    "\n",
    "# This file is part of the course DD2365 Advanced Computation in Fluid Mechanics\n",
    "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
    "#\n",
    "# This is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU Lesser General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# This template is maintained by Johan Hoffman\n",
    "# Please report problems to jhoffman@kth.se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28xLGz8JX3Hh"
   },
   "source": [
    "# **Set up environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2PYNusD08Wa"
   },
   "source": [
    "To have access to the neccessary modules you have to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xw7VlErAX7NS"
   },
   "outputs": [],
   "source": [
    "# Load neccessary modules.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gnO3lhAigLev"
   },
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l5zMzgPlRAF6"
   },
   "source": [
    "The problem investigated in this report is the implementation of sparse matrix-vector product, QR factorization, a direct solver for linear equations, and a solver for the least squares problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jOQvukXZq5U5"
   },
   "source": [
    "# **Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zF4iBj5VURZx"
   },
   "source": [
    "Numpy arrays are used to represent vectors and matrices. The algorithms are implemented by their description in the course literature. Each implementation is tested using known features of the algorithms, such that QR-factorization produces an orthogonal and upper diagonal matrix. Since finite precision arithmetic is not perfect, tests do not check for equality but that the result is close enough to what is desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse matrix-vector product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent sparse matrices using CRS. A matrix $A$ is a three tuple $(val, col\\_idx, row\\_ptr)$, where $val$ is all non-zero elements in the matrix, $col\\_idx$ contains the index of the column for each value in $val$ and $row\\_ptr$ contains integers pointing at the value in $val$ that starts each row by index. Since Python starts indexing at 0, I do the same for the indices stored in $col\\_idx$ and $row\\_ptr$. To get the matrix-vector product of $A$ and $x$, for each row we go through all non-zero elements and calculate the product with the corresponding element in $x$ and sum them up to get the inner product of $x$ with that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_matrix_vector_product(A, x):\n",
    "    val, col_idx, row_ptr = A\n",
    "    rows = len(row_ptr) - 1\n",
    "    b = np.zeros(rows)\n",
    "    for r in range(rows):\n",
    "        for i in range(row_ptr[r], row_ptr[r+1]):\n",
    "            col = col_idx[i]\n",
    "            b[r] += x[col] * val[i]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the function, we want to compare it to normal matrix vector multiplication. To be able to do this thoroughly, we implement a function that converts a numpy array matrix to a CRS triple. The value $-1$ is used to represent a row with no non-zero elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_sparse(A):\n",
    "    n, m = A.shape\n",
    "    val, col_idx, row_ptr = ([], [], [])\n",
    "    for r in range(len(A)):\n",
    "        row_ptr.append(-1)\n",
    "        for c in range(len(A[r])):\n",
    "            if A[r][c] != 0:\n",
    "                if row_ptr[r] == -1:\n",
    "                    row_ptr[r] = len(val)\n",
    "                val.append(A[r][c])\n",
    "                col_idx.append(c)\n",
    "    row_ptr.append(len(val))\n",
    "    return (val, col_idx, row_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now verify that our sparse matrix vector product is correct by comparing it to numpy's `matmul`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_sparse_matrix_vector_product(A, x):\n",
    "    sparse = dense_to_sparse(A)\n",
    "    assert np.linalg.norm(np.matmul(A, x) - sparse_matrix_vector_product(sparse, x)) < 1e-10\n",
    "\n",
    "def test_sparse_matrix_vector_product(tests, rows, cols):\n",
    "    for _ in range(tests):\n",
    "        test_mat = np.matrix.round(np.random.random((rows, cols)),1)\n",
    "        test_vec = np.matrix.round(np.random.random((cols,)),1)\n",
    "        verify_sparse_matrix_vector_product(test_mat, test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QR factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The QR factorization algorithm is implemented using the modified Gram-Schmidt iteration, where each new column of $A$ is iteratively projected to the orthogonal subspace of each column already added to $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_factorization(A):\n",
    "    rows, cols = A.shape\n",
    "    assert rows == cols, \"Non square matrix\"\n",
    "    Q = np.zeros(A.shape)\n",
    "    R = np.zeros(A.shape)\n",
    "    for j in range(cols):\n",
    "        v = A[:,j] \n",
    "        for i in range(j):\n",
    "            R[i,j] = np.dot(Q[:,i], v)\n",
    "            v = v - R[i,j]*Q[:,i]\n",
    "        R[j,j] = np.linalg.norm(v)\n",
    "        Q[:,j] = v/R[j,j]\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is verified in three ways. Firstly, we check that $R$ is upper triangular using numpy's `triu`. Secondly, we check that $Q$ is orthogonal, by checking that $Q^T = Q^{-1} \\Leftrightarrow QQ^T = I$. Lastly we check that $QR$ really is a factorization of $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_QR_factorization(A):\n",
    "    Q, R = QR_factorization(A)\n",
    "    rows = Q.shape[0]\n",
    "    assert np.array_equal(R, np.triu(R)), \"R is not upper triangular\"\n",
    "    assert np.linalg.norm(np.matmul(Q, Q.transpose()) - np.identity(rows)) < 1e-10, \"Q is not orthogonal\"\n",
    "    assert np.linalg.norm(np.matmul(Q, R) - A) < 1e-10, \"QR is not equal to A\"\n",
    "\n",
    "def test_QR_factorization(tests, rows):\n",
    "    for _ in range(tests):\n",
    "        test_mat = np.random.random((rows, rows))\n",
    "        verify_QR_factorization(test_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the linear equation $Ax = b$ we use QR-factorization. This gives us $QRx = b \\Leftrightarrow Rx = Q^{-1}b = Q^Tb$, which we can solve using backwards substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwards_substitution(U, b):\n",
    "    rows, cols = U.shape\n",
    "    assert rows == cols, \"Non square matrix\"\n",
    "    x = np.zeros(cols)\n",
    "    for i in range(rows - 1, -1, -1):\n",
    "        s = 0\n",
    "        for j in range(cols - 1, i, -1):\n",
    "            s += x[j]*U[i,j]\n",
    "        x[i] = (b[i] - s)/U[i,i]\n",
    "    return x\n",
    "\n",
    "def direct_solver(A, b):\n",
    "    Q, R = QR_factorization(A)\n",
    "    return backwards_substitution(R, np.matmul(Q.transpose(), b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the output we can simply check that $Ax = b \\Leftrightarrow ||Ax - b|| = 0$. Another test it to first generate $y$ and $A$, then calculating $b = Ay$ and checking that $x$ produced by our function is equal to $y$ (or that $||x - y|| = 0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_direct_solver(A, b):\n",
    "    x = direct_solver(A, b)\n",
    "    assert np.linalg.norm(np.matmul(A, x) - b) < 1e-10\n",
    "    \n",
    "def verify_direct_solver_2(A, y):\n",
    "    b = np.matmul(A, y)\n",
    "    x = direct_solver(A, b)\n",
    "    assert np.linalg.norm(x - y)\n",
    "    \n",
    "def test_direct_solver(tests, rows):\n",
    "    for _ in range(tests):\n",
    "        test_mat = np.random.random((rows, rows))\n",
    "        test_vec = np.random.random((rows,))\n",
    "        verify_direct_solver(test_mat, test_vec)\n",
    "        verify_direct_solver_2(test_mat, test_vec)\n",
    "        \n",
    "test_direct_solver(100, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least squares problem can easily be solved by transforming it into a normal linear equation by multiplying both sides by $A^T$. This equation can then be solved using our direct solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(A, b):\n",
    "    return direct_solver(np.matmul(A.transpose(), A), np.matmul(A.transpose(), b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_least_squares(A, b):\n",
    "    x = least_squares(A, b)\n",
    "    y = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "    assert np.abs(np.linalg.norm(np.matmul(A, x) - b) - np.linalg.norm(np.matmul(A, x) - b)) < 1e-10\n",
    "    \n",
    "def test_least_squares(tests, rows, cols):\n",
    "    for _ in range(tests):\n",
    "        test_mat = np.random.random((rows, cols))\n",
    "        test_vec = np.random.random((rows,))\n",
    "        verify_least_squares(test_mat, test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsQLT38gVbn_"
   },
   "source": [
    "# **Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code cell runs all test and shows that the implementions are successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK! completed all tests\n"
     ]
    }
   ],
   "source": [
    "test_sparse_matrix_vector_product(100, 30, 20)\n",
    "test_QR_factorization(100, 30)\n",
    "test_direct_solver(100, 30)\n",
    "test_least_squares(100, 20, 30)\n",
    "print(\"OK! completed all tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_4GLBv0zWr7m"
   },
   "source": [
    "# **Discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests are comprehensive enough to give a clear indication that the implementations are correct."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "template-report-lab-X.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
